{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjrKjSdlUnRM",
        "outputId": "e99ef1e7-3d5b-4a01-a983-04f63195adfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import albumentations as A\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "paPX1kji2hR_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)"
      ],
      "metadata": {
        "id": "Kf38oSXh3Vk1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9SInlyK3Wsh",
        "outputId": "3f5755c7-f617-4e70-af2c-b580970a6027"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 30\n",
        "num_workers = 2\n",
        "batch_size = 48\n",
        "lr = 1e-4\n",
        "early_stop = 5\n",
        "k_fold_num = 5\n",
        "model_name_ = \"swsl_resnext50_32x4d\""
      ],
      "metadata": {
        "id": "XXM5_wQL9dzQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader):\n",
        "    model = timm.create_model(model_name_, pretrained=True, num_classes=7).to(device)\n",
        "    class_num = [329, 205, 235, 134, 151, 245, 399]\n",
        "    class_weight = torch.tensor(np.max(class_num)/class_num).to(device, dtype=torch.float)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
        "\n",
        "    feat_extractor = [m for n, m in model.named_parameters() if \"fc\" not in n]\n",
        "    classifier = [p for p in model.fc.parameters()]\n",
        "    params = [\n",
        "        {\"params\": feat_extractor, \"lr\": lr*0.5},\n",
        "         {\"params\": classifier, \"lr\": lr}\n",
        "    ]\n",
        "    optimizer = Adam(params, lr=lr)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
        "\n",
        "    result = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": [], \"val_f1\": []}\n",
        "\n",
        "    train_loader = data_loader[\"train_loader\"]\n",
        "    val_loader = data_loader[\"val_loader\"]\n",
        "\n",
        "    for epoch_idx in range(1, epoch + 1):\n",
        "        model.train()\n",
        "\n",
        "        iter_train_loss = []\n",
        "        iter_val_loss = []\n",
        "        iter_val_acc = []\n",
        "        iter_val_f1 = []\n",
        "\n",
        "    for iter_idx, (train_imgs, train_labels) in enumerate(train_loader, 1):\n",
        "        train_imgs, train_labels = train_imgs.to(device, dtype=torch.float), train_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_pred = model(train_imgs)\n",
        "        train_loss = criterion(train_pred, train_labels)\n",
        "        train_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        iter_train_loss.append(train_loss.cpu().item())\n",
        "\n",
        "        print(f\"[Epoch {epoch_idx}/{epoch}] model training iteration {iter_idx}/{len(train_loader)}     \",\n",
        "                    end=\"\\r\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for iter_idx, (val_imgs, val_labels) in enumerate(val_loader, 1):\n",
        "                model.eval()\n",
        "\n",
        "                val_imgs, val_labels = val_imgs.to(device, dtype=torch.float), val_labels.to(device)\n",
        "\n",
        "                val_pred = model(val_imgs)\n",
        "                val_loss = criterion(val_pred, val_labels)\n",
        "\n",
        "                iter_val_loss.append(val_loss.cpu().item())\n",
        "\n",
        "                val_pred_c = val_pred.argmax(dim=1)\n",
        "                iter_val_acc.extend((val_pred_c == val_labels).cpu().tolist())\n",
        "\n",
        "                iter_f1_score = f1_score(y_true=val_labels.cpu().numpy(), y_pred=val_pred_c.cpu().numpy(), average=\"macro\")\n",
        "                iter_val_f1.append(iter_f1_score)\n",
        "\n",
        "                print(\n",
        "                  f\"[Epoch {epoch_idx}/{epoch}] model validation iteration {iter_idx}/{len(val_loader)}     \",\n",
        "                    end=\"\\r\"\n",
        "                )\n",
        "        epoch_train_loss = np.mean(iter_train_loss)\n",
        "        epoch_val_loss = np.mean(iter_val_loss)\n",
        "        epoch_val_acc = np.mean(iter_val_acc)\n",
        "        epoch_val_f1 = np.mean(iter_val_f1)\n",
        "\n",
        "        result[\"train_loss\"].append(epoch_train_loss)\n",
        "        result[\"val_loss\"].append(epoch_val_loss)\n",
        "        result[\"val_acc\"].append(epoch_val_acc)\n",
        "        result[\"val_f1\"].append(epoch_val_f1)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch_idx}/{epoch}] \"\n",
        "            f\"train loss : {epoch_train_loss:.4f} | \"\n",
        "            f\"valid loss : {epoch_val_loss:.4f} | valid acc : {epoch_val_acc:.2f}% | valid f1 score : {epoch_val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        Best_Model = None\n",
        "        Best_f1 = 0\n",
        "        stop_count = 0\n",
        "\n",
        "        if epoch_val_f1 > Best_f1:\n",
        "            Best_f1 = epoch_val_f1\n",
        "            Best_Model = model.state_dict()\n",
        "            stop_count = 0\n",
        "        else:\n",
        "            stop_count += 1\n",
        "\n",
        "        if stop_count == early_stop:\n",
        "            print(\"early stoped.\" + \" \" * 30)\n",
        "            break\n",
        "\n",
        "    return result, Best_Model"
      ],
      "metadata": {
        "id": "YJaPY5oU5jMX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_encoder = {\n",
        "    'dog': 0,\n",
        "    'elephant': 1,\n",
        "    'giraffe': 2,\n",
        "    'guitar': 3,\n",
        "    'horse': 4,\n",
        "    'house': 5,\n",
        "    'person': 6\n",
        "}\n",
        "\n",
        "def img_gather(img_path):\n",
        "    class_list = os.listdir(img_path)\n",
        "\n",
        "    file_lists = []\n",
        "    label_lists = []\n",
        "\n",
        "    for class_name in class_list:\n",
        "        file_list = os.listdir(os.path.join(img_path, class_name))\n",
        "        file_list = list(map(lambda x: \"/\".join([img_path] + [class_name] + [x]), file_list))\n",
        "        label_list = [class_encoder[class_name]] * len(file_list)\n",
        "\n",
        "        file_lists.extend(file_list)\n",
        "        label_lists.extend(label_list)\n",
        "\n",
        "    file_lists = np.array(file_lists)\n",
        "    label_lists = np.array(label_lists)\n",
        "\n",
        "    return file_lists, label_lists\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, file_lists, label_lists, transforms=None):\n",
        "        self.file_lists = file_lists.copy()\n",
        "        self.label_lists = label_lists.copy()\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.file_lists[idx], cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "        img = img.transpose(2, 0, 1)\n",
        "\n",
        "        label = self.label_lists[idx]\n",
        "\n",
        "        img = torch.tensor(img, dtype=torch.float)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        assert len(self.file_lists) == len(self.label_lists)\n",
        "        return len(self.file_lists)\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, file_lists, transforms=None):\n",
        "        self.file_lists = file_lists.copy()\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.file_lists[idx], cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "        img = img.transpose(2, 0, 1)\n",
        "\n",
        "        img = torch.tensor(img, dtype=torch.float)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_lists)"
      ],
      "metadata": {
        "id": "Fc82Y-1Z5mJT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = A.Compose([\n",
        "    A.Rotate(),\n",
        "    A.HorizontalFlip(),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    A.Normalize()\n",
        "])\n",
        "\n",
        "valid_transforms = A.Compose([\n",
        "    A.Normalize()\n",
        "])\n",
        "data_lists, data_labels = img_gather(\"/content/drive/MyDrive/train\")\n",
        "\n",
        "best_models = []\n",
        "k_fold_num = k_fold_num\n",
        "\n",
        "if k_fold_num == -1:\n",
        "    train_lists, valid_lists, train_labels, valid_labels = train_test_split(data_lists, data_labels, train_size=0.8,\n",
        "                                                                            shuffle=True, random_state=random_seed,\n",
        "                                                                            stratify=data_labels)\n",
        "\n",
        "    train_dataset = TrainDataset(file_lists=train_lists, label_lists=train_labels, transforms=train_transforms)\n",
        "    valid_dataset = TrainDataset(file_lists=valid_lists, label_lists=valid_labels, transforms=valid_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    data_loader = {\"train_loader\": train_loader, \"valid_loader\": valid_loader}\n",
        "\n",
        "    print(\"No fold training starts ... \")\n",
        "    train_result, best_model = train(data_loader)\n",
        "\n",
        "    best_models.append(best_model)\n",
        "\n",
        "else:\n",
        "    skf = StratifiedKFold(n_splits=k_fold_num, random_state=random_seed, shuffle=True)\n",
        "\n",
        "    print(f\"{k_fold_num} fold training starts ... \")\n",
        "    for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(data_lists, data_labels), 1):\n",
        "        print(f\"- {fold_idx} fold -\")\n",
        "        train_lists, train_labels = data_lists[train_idx], data_labels[train_idx]\n",
        "        val_lists, valid_labels = data_lists[valid_idx], data_labels[valid_idx]\n",
        "\n",
        "        train_dataset = TrainDataset(file_lists=train_lists, label_lists=train_labels, transforms=train_transforms)\n",
        "        val_dataset = TrainDataset(file_lists=val_lists, label_lists=valid_labels, transforms=valid_transforms)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        data_loader = {\"train_loader\": train_loader, \"val_loader\": val_loader}\n",
        "\n",
        "        train_result, best_model = train(data_loader)\n",
        "\n",
        "        best_models.append(best_model)\n",
        "\n",
        "        model_save_path = f\"best_model_fold_{fold_idx}.pt\"\n",
        "        torch.save(best_model, model_save_path)\n",
        "        print(f\"Saved model for fold {fold_idx} to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZkhx8tr5un9",
        "outputId": "aff7867d-41a9-476f-a73b-6162283430d1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 fold training starts ... \n",
            "- 1 fold -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30/30] train loss : 2.0016 | valid loss : 1.8884 | valid acc : 0.20% | valid f1 score : 0.1149\n",
            "[Epoch 30/30] train loss : 1.9265 | valid loss : 1.8251 | valid acc : 0.25% | valid f1 score : 0.1644\n",
            "[Epoch 30/30] train loss : 1.8860 | valid loss : 1.7251 | valid acc : 0.36% | valid f1 score : 0.2813\n",
            "[Epoch 30/30] train loss : 1.8106 | valid loss : 1.6111 | valid acc : 0.46% | valid f1 score : 0.3631\n",
            "[Epoch 30/30] train loss : 1.7158 | valid loss : 1.4854 | valid acc : 0.54% | valid f1 score : 0.4662\n",
            "[Epoch 30/30] train loss : 1.6067 | valid loss : 1.3774 | valid acc : 0.60% | valid f1 score : 0.5325\n",
            "[Epoch 30/30] train loss : 1.5204 | valid loss : 1.2807 | valid acc : 0.64% | valid f1 score : 0.5797\n",
            "[Epoch 30/30] train loss : 1.4240 | valid loss : 1.1932 | valid acc : 0.67% | valid f1 score : 0.6116\n",
            "[Epoch 30/30] train loss : 1.3563 | valid loss : 1.1230 | valid acc : 0.69% | valid f1 score : 0.6371\n",
            "[Epoch 30/30] train loss : 1.2753 | valid loss : 1.0618 | valid acc : 0.71% | valid f1 score : 0.6619\n",
            "[Epoch 30/30] train loss : 1.2101 | valid loss : 1.0130 | valid acc : 0.73% | valid f1 score : 0.6785\n",
            "[Epoch 30/30] train loss : 1.1766 | valid loss : 0.9675 | valid acc : 0.74% | valid f1 score : 0.6962\n",
            "[Epoch 30/30] train loss : 1.1357 | valid loss : 0.9250 | valid acc : 0.76% | valid f1 score : 0.7151\n",
            "[Epoch 30/30] train loss : 1.1164 | valid loss : 0.8828 | valid acc : 0.77% | valid f1 score : 0.7329\n",
            "[Epoch 30/30] train loss : 1.0784 | valid loss : 0.8478 | valid acc : 0.78% | valid f1 score : 0.7417\n",
            "[Epoch 30/30] train loss : 1.0410 | valid loss : 0.8180 | valid acc : 0.79% | valid f1 score : 0.7488\n",
            "[Epoch 30/30] train loss : 1.0413 | valid loss : 0.7881 | valid acc : 0.79% | valid f1 score : 0.7555\n",
            "[Epoch 30/30] train loss : 1.0124 | valid loss : 0.7618 | valid acc : 0.80% | valid f1 score : 0.7620\n",
            "[Epoch 30/30] train loss : 0.9837 | valid loss : 0.7419 | valid acc : 0.80% | valid f1 score : 0.7681\n",
            "[Epoch 30/30] train loss : 0.9666 | valid loss : 0.7149 | valid acc : 0.81% | valid f1 score : 0.7755\n",
            "[Epoch 30/30] train loss : 0.9328 | valid loss : 0.6880 | valid acc : 0.81% | valid f1 score : 0.7836\n",
            "[Epoch 30/30] train loss : 0.9052 | valid loss : 0.6648 | valid acc : 0.82% | valid f1 score : 0.7901\n",
            "[Epoch 30/30] train loss : 0.8807 | valid loss : 0.6429 | valid acc : 0.83% | valid f1 score : 0.7961\n",
            "[Epoch 30/30] train loss : 0.8683 | valid loss : 0.6210 | valid acc : 0.83% | valid f1 score : 0.8024\n",
            "[Epoch 30/30] train loss : 0.8446 | valid loss : 0.6006 | valid acc : 0.84% | valid f1 score : 0.8090\n",
            "[Epoch 30/30] train loss : 0.8234 | valid loss : 0.5822 | valid acc : 0.84% | valid f1 score : 0.8149\n",
            "[Epoch 30/30] train loss : 0.8027 | valid loss : 0.5659 | valid acc : 0.84% | valid f1 score : 0.8197\n",
            "[Epoch 30/30] train loss : 0.7869 | valid loss : 0.5511 | valid acc : 0.85% | valid f1 score : 0.8238\n",
            "[Epoch 30/30] train loss : 0.7825 | valid loss : 0.5374 | valid acc : 0.85% | valid f1 score : 0.8274\n",
            "Saved model for fold 1 to best_model_fold_1.pt\n",
            "- 2 fold -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30/30] train loss : 1.9346 | valid loss : 1.8421 | valid acc : 0.30% | valid f1 score : 0.1773\n",
            "[Epoch 30/30] train loss : 1.8767 | valid loss : 1.8184 | valid acc : 0.34% | valid f1 score : 0.2201\n",
            "[Epoch 30/30] train loss : 1.8979 | valid loss : 1.7207 | valid acc : 0.41% | valid f1 score : 0.2812\n",
            "[Epoch 30/30] train loss : 1.7925 | valid loss : 1.6574 | valid acc : 0.45% | valid f1 score : 0.3369\n",
            "[Epoch 30/30] train loss : 1.7705 | valid loss : 1.5876 | valid acc : 0.48% | valid f1 score : 0.3735\n",
            "[Epoch 30/30] train loss : 1.6749 | valid loss : 1.5106 | valid acc : 0.51% | valid f1 score : 0.4170\n",
            "[Epoch 30/30] train loss : 1.6014 | valid loss : 1.4409 | valid acc : 0.53% | valid f1 score : 0.4498\n",
            "[Epoch 30/30] train loss : 1.5447 | valid loss : 1.3787 | valid acc : 0.56% | valid f1 score : 0.4768\n",
            "[Epoch 30/30] train loss : 1.4760 | valid loss : 1.3300 | valid acc : 0.58% | valid f1 score : 0.5004\n",
            "[Epoch 30/30] train loss : 1.4369 | valid loss : 1.2802 | valid acc : 0.60% | valid f1 score : 0.5251\n",
            "[Epoch 30/30] train loss : 1.4047 | valid loss : 1.2435 | valid acc : 0.61% | valid f1 score : 0.5408\n",
            "[Epoch 30/30] train loss : 1.3543 | valid loss : 1.2077 | valid acc : 0.62% | valid f1 score : 0.5587\n",
            "[Epoch 30/30] train loss : 1.3103 | valid loss : 1.1750 | valid acc : 0.64% | valid f1 score : 0.5738\n",
            "[Epoch 30/30] train loss : 1.2772 | valid loss : 1.1344 | valid acc : 0.66% | valid f1 score : 0.5956\n",
            "[Epoch 30/30] train loss : 1.2428 | valid loss : 1.1010 | valid acc : 0.67% | valid f1 score : 0.6138\n",
            "[Epoch 30/30] train loss : 1.2146 | valid loss : 1.0768 | valid acc : 0.68% | valid f1 score : 0.6252\n",
            "[Epoch 30/30] train loss : 1.1926 | valid loss : 1.0619 | valid acc : 0.69% | valid f1 score : 0.6312\n",
            "[Epoch 30/30] train loss : 1.1708 | valid loss : 1.0406 | valid acc : 0.70% | valid f1 score : 0.6384\n",
            "[Epoch 30/30] train loss : 1.1507 | valid loss : 1.0065 | valid acc : 0.71% | valid f1 score : 0.6497\n",
            "[Epoch 30/30] train loss : 1.1341 | valid loss : 0.9703 | valid acc : 0.72% | valid f1 score : 0.6572\n",
            "[Epoch 30/30] train loss : 1.1022 | valid loss : 0.9747 | valid acc : 0.72% | valid f1 score : 0.6589\n",
            "[Epoch 30/30] train loss : 1.1101 | valid loss : 0.9441 | valid acc : 0.72% | valid f1 score : 0.6705\n",
            "[Epoch 30/30] train loss : 1.0779 | valid loss : 0.9233 | valid acc : 0.73% | valid f1 score : 0.6780\n",
            "[Epoch 30/30] train loss : 1.0438 | valid loss : 0.9223 | valid acc : 0.74% | valid f1 score : 0.6811\n",
            "[Epoch 30/30] train loss : 1.0389 | valid loss : 0.9164 | valid acc : 0.74% | valid f1 score : 0.6834\n",
            "[Epoch 30/30] train loss : 1.0423 | valid loss : 0.9007 | valid acc : 0.75% | valid f1 score : 0.6900\n",
            "[Epoch 30/30] train loss : 1.0457 | valid loss : 0.8806 | valid acc : 0.75% | valid f1 score : 0.6970\n",
            "[Epoch 30/30] train loss : 1.0258 | valid loss : 0.8602 | valid acc : 0.76% | valid f1 score : 0.7045\n",
            "[Epoch 30/30] train loss : 1.0046 | valid loss : 0.8392 | valid acc : 0.76% | valid f1 score : 0.7119\n",
            "Saved model for fold 2 to best_model_fold_2.pt\n",
            "- 3 fold -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30/30] train loss : 1.9226 | valid loss : 1.8568 | valid acc : 0.29% | valid f1 score : 0.2285\n",
            "[Epoch 30/30] train loss : 1.8632 | valid loss : 1.7719 | valid acc : 0.34% | valid f1 score : 0.2701\n",
            "[Epoch 30/30] train loss : 1.8754 | valid loss : 1.6930 | valid acc : 0.40% | valid f1 score : 0.3135\n",
            "[Epoch 30/30] train loss : 1.8168 | valid loss : 1.6038 | valid acc : 0.46% | valid f1 score : 0.3890\n",
            "[Epoch 30/30] train loss : 1.7633 | valid loss : 1.5200 | valid acc : 0.51% | valid f1 score : 0.4444\n",
            "[Epoch 30/30] train loss : 1.6994 | valid loss : 1.4259 | valid acc : 0.57% | valid f1 score : 0.5136\n",
            "[Epoch 30/30] train loss : 1.6076 | valid loss : 1.3443 | valid acc : 0.61% | valid f1 score : 0.5657\n",
            "[Epoch 30/30] train loss : 1.5485 | valid loss : 1.2693 | valid acc : 0.65% | valid f1 score : 0.6075\n",
            "[Epoch 30/30] train loss : 1.4848 | valid loss : 1.2111 | valid acc : 0.68% | valid f1 score : 0.6383\n",
            "[Epoch 30/30] train loss : 1.4284 | valid loss : 1.1590 | valid acc : 0.71% | valid f1 score : 0.6680\n",
            "[Epoch 30/30] train loss : 1.3845 | valid loss : 1.1168 | valid acc : 0.73% | valid f1 score : 0.6922\n",
            "[Epoch 30/30] train loss : 1.3406 | valid loss : 1.0814 | valid acc : 0.74% | valid f1 score : 0.7129\n",
            "[Epoch 30/30] train loss : 1.2992 | valid loss : 1.0466 | valid acc : 0.76% | valid f1 score : 0.7312\n",
            "[Epoch 30/30] train loss : 1.2636 | valid loss : 1.0109 | valid acc : 0.77% | valid f1 score : 0.7458\n",
            "[Epoch 30/30] train loss : 1.2318 | valid loss : 0.9768 | valid acc : 0.78% | valid f1 score : 0.7554\n",
            "[Epoch 30/30] train loss : 1.1872 | valid loss : 0.9586 | valid acc : 0.78% | valid f1 score : 0.7520\n",
            "[Epoch 30/30] train loss : 1.1465 | valid loss : 0.9310 | valid acc : 0.78% | valid f1 score : 0.7547\n",
            "[Epoch 30/30] train loss : 1.1414 | valid loss : 0.9010 | valid acc : 0.79% | valid f1 score : 0.7573\n",
            "[Epoch 30/30] train loss : 1.1061 | valid loss : 0.8783 | valid acc : 0.79% | valid f1 score : 0.7610\n",
            "[Epoch 30/30] train loss : 1.0819 | valid loss : 0.8752 | valid acc : 0.79% | valid f1 score : 0.7600\n",
            "[Epoch 30/30] train loss : 1.1107 | valid loss : 0.8517 | valid acc : 0.80% | valid f1 score : 0.7669\n",
            "[Epoch 30/30] train loss : 1.0998 | valid loss : 0.8296 | valid acc : 0.80% | valid f1 score : 0.7722\n",
            "[Epoch 30/30] train loss : 1.0777 | valid loss : 0.8081 | valid acc : 0.80% | valid f1 score : 0.7761\n",
            "[Epoch 30/30] train loss : 1.0581 | valid loss : 0.7939 | valid acc : 0.81% | valid f1 score : 0.7751\n",
            "[Epoch 30/30] train loss : 1.0532 | valid loss : 0.7748 | valid acc : 0.81% | valid f1 score : 0.7774\n",
            "[Epoch 30/30] train loss : 1.0419 | valid loss : 0.7526 | valid acc : 0.81% | valid f1 score : 0.7836\n",
            "[Epoch 30/30] train loss : 1.0123 | valid loss : 0.7320 | valid acc : 0.82% | valid f1 score : 0.7899\n",
            "[Epoch 30/30] train loss : 0.9891 | valid loss : 0.7146 | valid acc : 0.82% | valid f1 score : 0.7947\n",
            "[Epoch 30/30] train loss : 0.9591 | valid loss : 0.6982 | valid acc : 0.83% | valid f1 score : 0.8001\n",
            "Saved model for fold 3 to best_model_fold_3.pt\n",
            "- 4 fold -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30/30] train loss : 1.9182 | valid loss : 1.7977 | valid acc : 0.37% | valid f1 score : 0.2232\n",
            "[Epoch 30/30] train loss : 1.8654 | valid loss : 1.7722 | valid acc : 0.31% | valid f1 score : 0.1857\n",
            "[Epoch 30/30] train loss : 1.7887 | valid loss : 1.6706 | valid acc : 0.39% | valid f1 score : 0.3188\n",
            "[Epoch 30/30] train loss : 1.7553 | valid loss : 1.6108 | valid acc : 0.40% | valid f1 score : 0.3491\n",
            "[Epoch 30/30] train loss : 1.7304 | valid loss : 1.4989 | valid acc : 0.46% | valid f1 score : 0.4207\n",
            "[Epoch 30/30] train loss : 1.6408 | valid loss : 1.4066 | valid acc : 0.53% | valid f1 score : 0.4883\n",
            "[Epoch 30/30] train loss : 1.5517 | valid loss : 1.3321 | valid acc : 0.57% | valid f1 score : 0.5308\n",
            "[Epoch 30/30] train loss : 1.4741 | valid loss : 1.2721 | valid acc : 0.61% | valid f1 score : 0.5668\n",
            "[Epoch 30/30] train loss : 1.4248 | valid loss : 1.2141 | valid acc : 0.64% | valid f1 score : 0.5973\n",
            "[Epoch 30/30] train loss : 1.3518 | valid loss : 1.1630 | valid acc : 0.67% | valid f1 score : 0.6266\n",
            "[Epoch 30/30] train loss : 1.3004 | valid loss : 1.1238 | valid acc : 0.69% | valid f1 score : 0.6517\n",
            "[Epoch 30/30] train loss : 1.2628 | valid loss : 1.0886 | valid acc : 0.71% | valid f1 score : 0.6707\n",
            "[Epoch 30/30] train loss : 1.2159 | valid loss : 1.0545 | valid acc : 0.72% | valid f1 score : 0.6902\n",
            "[Epoch 30/30] train loss : 1.1717 | valid loss : 1.0155 | valid acc : 0.74% | valid f1 score : 0.7078\n",
            "[Epoch 30/30] train loss : 1.1334 | valid loss : 0.9742 | valid acc : 0.75% | valid f1 score : 0.7221\n",
            "[Epoch 30/30] train loss : 1.0895 | valid loss : 0.9401 | valid acc : 0.76% | valid f1 score : 0.7235\n",
            "[Epoch 30/30] train loss : 1.0682 | valid loss : 0.9057 | valid acc : 0.76% | valid f1 score : 0.7297\n",
            "[Epoch 30/30] train loss : 1.0404 | valid loss : 0.8665 | valid acc : 0.77% | valid f1 score : 0.7392\n",
            "[Epoch 30/30] train loss : 1.0087 | valid loss : 0.8619 | valid acc : 0.77% | valid f1 score : 0.7415\n",
            "[Epoch 30/30] train loss : 0.9970 | valid loss : 0.8414 | valid acc : 0.78% | valid f1 score : 0.7478\n",
            "[Epoch 30/30] train loss : 0.9698 | valid loss : 0.8156 | valid acc : 0.79% | valid f1 score : 0.7553\n",
            "[Epoch 30/30] train loss : 0.9405 | valid loss : 0.7918 | valid acc : 0.79% | valid f1 score : 0.7599\n",
            "[Epoch 30/30] train loss : 0.9115 | valid loss : 0.7749 | valid acc : 0.79% | valid f1 score : 0.7623\n",
            "[Epoch 30/30] train loss : 0.8918 | valid loss : 0.7541 | valid acc : 0.80% | valid f1 score : 0.7674\n",
            "[Epoch 30/30] train loss : 0.8839 | valid loss : 0.7354 | valid acc : 0.80% | valid f1 score : 0.7700\n",
            "[Epoch 30/30] train loss : 0.8701 | valid loss : 0.7199 | valid acc : 0.81% | valid f1 score : 0.7739\n",
            "[Epoch 30/30] train loss : 0.8552 | valid loss : 0.7039 | valid acc : 0.81% | valid f1 score : 0.7785\n",
            "[Epoch 30/30] train loss : 0.8396 | valid loss : 0.6872 | valid acc : 0.81% | valid f1 score : 0.7832\n",
            "[Epoch 30/30] train loss : 0.8205 | valid loss : 0.6706 | valid acc : 0.82% | valid f1 score : 0.7885\n",
            "Saved model for fold 4 to best_model_fold_4.pt\n",
            "- 5 fold -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30/30] train loss : 1.9065 | valid loss : 1.9062 | valid acc : 0.21% | valid f1 score : 0.1127\n",
            "[Epoch 30/30] train loss : 1.8850 | valid loss : 1.8174 | valid acc : 0.29% | valid f1 score : 0.1696\n",
            "[Epoch 30/30] train loss : 1.9101 | valid loss : 1.7464 | valid acc : 0.30% | valid f1 score : 0.1981\n",
            "[Epoch 30/30] train loss : 1.8453 | valid loss : 1.6896 | valid acc : 0.32% | valid f1 score : 0.2305\n",
            "[Epoch 30/30] train loss : 1.7699 | valid loss : 1.6137 | valid acc : 0.39% | valid f1 score : 0.3014\n",
            "[Epoch 30/30] train loss : 1.7134 | valid loss : 1.5223 | valid acc : 0.46% | valid f1 score : 0.3687\n",
            "[Epoch 30/30] train loss : 1.6461 | valid loss : 1.4372 | valid acc : 0.52% | valid f1 score : 0.4410\n",
            "[Epoch 30/30] train loss : 1.5682 | valid loss : 1.3620 | valid acc : 0.57% | valid f1 score : 0.4965\n",
            "[Epoch 30/30] train loss : 1.5057 | valid loss : 1.3032 | valid acc : 0.60% | valid f1 score : 0.5370\n",
            "[Epoch 30/30] train loss : 1.4430 | valid loss : 1.2559 | valid acc : 0.63% | valid f1 score : 0.5669\n",
            "[Epoch 30/30] train loss : 1.3793 | valid loss : 1.2119 | valid acc : 0.66% | valid f1 score : 0.5965\n",
            "[Epoch 30/30] train loss : 1.3436 | valid loss : 1.1765 | valid acc : 0.68% | valid f1 score : 0.6225\n",
            "[Epoch 30/30] train loss : 1.3077 | valid loss : 1.1383 | valid acc : 0.70% | valid f1 score : 0.6453\n",
            "[Epoch 30/30] train loss : 1.2676 | valid loss : 1.1030 | valid acc : 0.71% | valid f1 score : 0.6625\n",
            "[Epoch 30/30] train loss : 1.2274 | valid loss : 1.0678 | valid acc : 0.73% | valid f1 score : 0.6728\n",
            "[Epoch 30/30] train loss : 1.1932 | valid loss : 1.0339 | valid acc : 0.73% | valid f1 score : 0.6840\n",
            "[Epoch 30/30] train loss : 1.1699 | valid loss : 0.9918 | valid acc : 0.74% | valid f1 score : 0.6936\n",
            "[Epoch 30/30] train loss : 1.1320 | valid loss : 0.9481 | valid acc : 0.75% | valid f1 score : 0.7071\n",
            "[Epoch 30/30] train loss : 1.1060 | valid loss : 0.9109 | valid acc : 0.76% | valid f1 score : 0.7178\n",
            "[Epoch 30/30] train loss : 1.0876 | valid loss : 0.8909 | valid acc : 0.77% | valid f1 score : 0.7247\n",
            "[Epoch 30/30] train loss : 1.0674 | valid loss : 0.8702 | valid acc : 0.78% | valid f1 score : 0.7308\n",
            "[Epoch 30/30] train loss : 1.0446 | valid loss : 0.8543 | valid acc : 0.78% | valid f1 score : 0.7331\n",
            "[Epoch 30/30] train loss : 1.0428 | valid loss : 0.8258 | valid acc : 0.78% | valid f1 score : 0.7412\n",
            "[Epoch 30/30] train loss : 1.0431 | valid loss : 0.8066 | valid acc : 0.79% | valid f1 score : 0.7456\n",
            "[Epoch 30/30] train loss : 1.0293 | valid loss : 0.7901 | valid acc : 0.79% | valid f1 score : 0.7492\n",
            "[Epoch 30/30] train loss : 1.0178 | valid loss : 0.7693 | valid acc : 0.80% | valid f1 score : 0.7556\n",
            "[Epoch 30/30] train loss : 0.9913 | valid loss : 0.7495 | valid acc : 0.80% | valid f1 score : 0.7622\n",
            "[Epoch 30/30] train loss : 0.9708 | valid loss : 0.7361 | valid acc : 0.81% | valid f1 score : 0.7656\n",
            "[Epoch 30/30] train loss : 0.9469 | valid loss : 0.7200 | valid acc : 0.81% | valid f1 score : 0.7687\n",
            "Saved model for fold 5 to best_model_fold_5.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = A.Compose([\n",
        "    A.Normalize()\n",
        "])\n",
        "\n",
        "test_files = os.listdir(\"/content/drive/MyDrive/test/test_image\")\n",
        "test_files = sorted(test_files)\n",
        "test_files = list(map(lambda x: \"/\".join([\"/content/drive/MyDrive/test/test_image\", x]), test_files))\n",
        "\n",
        "test_dataset = TestDataset(file_lists=test_files, transforms=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "answer_logits = []\n",
        "\n",
        "model = timm.create_model(model_name_, pretrained=True, num_classes=7).to(device=device)\n",
        "\n",
        "for fold_idx, best_model in enumerate(best_models, 1):\n",
        "    model.load_state_dict(best_model)\n",
        "    model.eval()\n",
        "\n",
        "    fold_logits = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for iter_idx, test_imgs in enumerate(test_loader, 1):\n",
        "            test_imgs = test_imgs.to(device)\n",
        "\n",
        "            test_pred = model(test_imgs)\n",
        "            fold_logits.extend(test_pred.cpu().tolist())\n",
        "\n",
        "            print(f\"[{fold_idx} fold] inference iteration {iter_idx}/{len(test_loader)}\" + \" \" * 10, end=\"\\r\")\n",
        "\n",
        "    answer_logits.append(fold_logits)\n",
        "\n",
        "answer_logits = np.mean(answer_logits, axis=0)\n",
        "answer_value = np.argmax(answer_logits, axis=-1)\n",
        "\n",
        "i = 0\n",
        "while True:\n",
        "    if not os.path.isfile(os.path.join(\"submissions\", f\"submission_{i}.csv\")):\n",
        "        submission_path = os.path.join(\"submissions\", f\"submission_{i}.csv\")\n",
        "        os.makedirs(\"submissions\", exist_ok=True)\n",
        "        break\n",
        "    i += 1\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/test_answer_sample_.csv'\n",
        "submission = pd.read_csv(csv_path, index_col=False)\n",
        "submission[\"answer value\"] = answer_value\n",
        "submission[\"answer value\"].to_csv(submission_path)\n",
        "print(\"\\nAll done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twuw6PP5vIz",
        "outputId": "8ce1fa53-c238-4ae8-a166-5b82d78832d5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 fold] inference iteration 8/8          \n",
            "All done.\n"
          ]
        }
      ]
    }
  ]
}